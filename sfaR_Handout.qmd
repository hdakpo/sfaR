---\ntitle: "Stochastic Frontier Analysis Using sfaR"\nsubtitle: "A Comprehensive Guide to the sfaR R Package"\nauthor:\n  - name: "K Hervé Dakpo"\n    orcid: "0000-0002-6114-7896"\n    affiliation: "Université Paris-Saclay INRAE, AgroParisTech, PSAE"\n    email: "k-herve.dakpo@inrae.fr"\n    url: "https://www6.versailles-grignon.inrae.fr/psae_eng/PersonalPages2/Herve-Dakpo"\n  - name: "Yann Desjeux"\n    affiliation: "INRAE, Bordeaux School of Economics, University Bordeaux"\n  - name: "Arne Henningsen"\n    orcid: "0000-0002-6720-0264"\n    affiliation: "Dept. of Food and Resource Economics, University of Copenhagen"\n  - name: "Laure Latruffe"\n    affiliation: "INRAE, Bordeaux School of Economics, University Bordeaux"\ndate: today\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    code-fold: true\n    theme: cosmo\n    css: custom.css\n    html-math-method: mathjax\n  pdf:\n    documentclass: article\n    geometry: \n      - margin=1in\n      - headheight=15pt\n    keep-tex: true\n    include-in-header:\n      - text: |\n          \usepackage{amsmath,amssymb,amsthm,bm}\n          \usepackage{xcolor}\n          \usepackage{soul}\n          \definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}\n          \definecolor{darkblue}{rgb}{0.0, 0.0, 0.55}\n          \newcommand{\sfar}{\textbf{sfaR}}\n          \newcommand{\pkg}[1]{\textbf{#1}}\n          \newcommand{\proglang}[1]{\textbf{#1}}\nbibliography: sfaR-bib.bib\ncsl: american-statistical-association.csl\nexecute:\n  echo: true\n  warning: false\n  message: false\n  cache: true\ncrossref:\n  eq-prefix: ""\n  fig-prefix: "Figure"\n  tbl-prefix: "Table"\n---\n\n## Abstract {.unnumbered}\n\nThis article presents an overview of the **sfaR** **R** package, designed for advanced estimation of stochastic frontier (SF) models. Extending beyond the widely used **frontier** package, **sfaR** incorporates recent developments for both cross-sectional and panel data SF models. Key features include support for latent-class SF models and several specialized variants—such as zero-inefficiency, contaminated noise, and multimodal inefficiency SF models—as well as metafrontier and sample-selection SF models. Users can choose from a variety of one-sided error term distributions (e.g., half-normal, truncated normal, exponential, Rayleigh, generalized exponential, skewed-laplace, uniform, gamma, Weibull, log-normal, folded normal, and weighted exponential). Additionally, **sfaR** provides flexible optimization algorithms to improve model estimation. This article outlines the primary functions of **sfaR** and demonstrates their application with real-world data.\n\n**Keywords:** stochastic frontier analysis, latent class stochastic frontier, metafrontier, sample selection stochastic frontier, zero inefficiency stochastic frontier, cross-sectional data, panel data, R\n\n```{r}\n#| label: setup\n#| include: false\n\n# Load required packages\nif (!require(sfaR)) {\n  if (!require(devtools)) {\n    install.packages("devtools")\n    library(devtools)\n  }\n  install_github("hdakpo/sfaR")\n}\nlibrary(sfaR)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Set global options\noptions(digits = 4)\nknitr::opts_chunk$set(\n  comment = "#>",\n  collapse = TRUE,\n  cache = FALSE,\n  out.width = "70%",\n  fig.align = 'center',\n  fig.width = 6,\n  fig.asp = 0.618\n)\n```\n\n# Introduction {#sec-intro}\n\nSince its inception by @aig77, @mee77, and @batt77 over 40 years ago, stochastic frontier analysis (SFA) has been widely used for benchmarking various performance aspects across diverse decision-making units (DMUs). Over time, numerous extensions have been developed to accommodate different scenarios, such as data types, technological heterogeneity, and endogeneity. SFA is instrumental in evaluating performance indicators (e.g., technical and economic efficiencies, productivity) of DMUs, allowing for performance comparisons, identification of underperformers, and insights from best practices. This process is essential in crafting policies that enhance efficiency in both the private and public sectors [@par14].\n\nSFA has diverse applications, including measuring productivity growth [e.g., @orea02], analyzing the effects of regulation and competition [e.g., @myd20; @kang02], assessing eco-efficiency [e.g., @mada23], and examining environmental factors' impacts [e.g., @li19]. It has been used across various sectors, such as agriculture [e.g., @latruffe23], banking [e.g., @badu21], education [e.g., @aga19], energy [e.g., @filipp15; @kop11], healthcare [e.g., @ji20], manufacturing [e.g., @boy19], museums [e.g., @price23], and transportation [e.g., @coelli99; @filipp16].\n\nThe scope of SFA spans pure research, business applications, and policymaking. The **sfaR** package aims to support fundamental SFA methods and recent advances in this field through the **R** software environment.^[SFA has also been implemented in other software, such as **Limdep**, **Stata**, and **Ox**.] The **frontier** package [@frontier] has been the primary open-source software for SF model estimation in R,^[The **frontier** package is based on the Fortran source code of **Frontier 4.1**, developed by Tim Coelli.] but it is limited to a few distributions for the inefficiency term and a few panel data models, supporting only half-normal and truncated normal distributions. Additionally, it offers only basic panel models: the time-invariant inefficiency model [@pl81] and the time-varying efficiency model [@batco92]. By contrast, **sfaR** includes further time-varying inefficiency models [@kum90; @batco92; @lees93; @cue00; @cue02; @feng09; @kw05; @al06].\n\nRecently, the **npsf** package [@npsf] has expanded on frontier by introducing new panel-data models, such as the generalized true random effects models [e.g., @colomb14; @klh14; @tk14].^[Many other packages are available, such as **Benchmarking** [@bench] with basic SFA models, **sfadv** [@sfadv] addressing endogeneity in SFA, **semsfa** [@semsfa] and **dsfa** [@dsfa] with semi- and non-parametric models, and **ssfa** [@ssfa] for spatial stochastic frontiers. Online R codes also exist for SFA [@si20; @si22; @nguyen22].] However, recent developments, especially for technological heterogeneity remain underrepresented. For example, latent-class stochastic frontier models and their variants are not covered in these packages. The **sfaR** package includes not only standard latent-class SF models but also zero-inefficiency, contaminated-noise, multimodal inefficiency SF models [@orea04; @greene05; @kum13; @rho15; @wheat19], as well as metafrontier estimation [@batt04; @huang14; @am17] and sample-selection SF [@greene10].\n\nWhile **sfaR** does not yet cover every SF model developed over the past four decades, it is a significant step forward, with potential for growth and contributions from other developers. Currently, the package supports both cross-sectional and panel data, offers a broader selection of distributions for the inefficiency term, and provides multiple optimization algorithms. With 296 likelihood functions implemented, organized into ten main functions, **sfaR** provides a powerful tool for model estimation. This article describes each model group and demonstrates their use with real-life data.\n\nThe structure of the paper is as follows: @sec-modelstandacross presents a brief overview of standard SF models for cross-sectional and panel data. @sec-modelcm covers latent class SF models and their variants. @sec-other discusses other SF models, such as metafrontiers and sample selection SF. @sec-prespackage details the main functions and post-estimation routines of **sfaR**, and @sec-illus provides empirical applications. The final section offers discussions and conclusions.\n\n# Standard cross-sectional SFA models {#sec-modelstandacross}\n\nWe consider a general stochastic frontier model:^[For example, in case of a production frontier, the dependent variable represents the output quantity, while the explanatory variables represent the input quantities. In case of a cost function, the dependent variable indicates the costs, while the explanatory variables represent the input prices and the output quantities. Further types of functions that can be modeled as stochastic frontiers are, e.g., distance functions, profit functions, revenue functions, and input requirement functions.] \n\n$$y_i = \mathbf{x_i}'\boldsymbol{\beta} + v_i - S \, u_i \quad \text{with} \quad i = 1, \ldots, N$$ {#eq-basic-sf}\n\nwhere subscript $i$ indicates the observation, $N$ indicates the total number of observations, $y_i$ is the dependent variable, $\mathbf{x_i}$ is a vector of explanatory variables, $\boldsymbol{\beta}$ is a vector of unknown coefficients, $v_i$ is a two-sided ("noise") error term that is usually assumed to follow a normal distribution $\mathcal{N}(0, \sigma_v^2)$, $u_i$ is a one-sided ("inefficiency") error term, and $S = 1$ specifies a production frontier, while $S = -1$ specifies a cost frontier.\n\nThe spearhead for the SFA is the assumption regarding the distribution of the inefficiency term $u \geq 0$. Users of the **sfaR** package can choose among ten different distributions of $u$ for standard SF models. @tbl-distributions presents the density functions of all the ten distributions implemented in the **sfaR** package.^[Moments associated with each distribution can be found in Tables A.1, A.2, and A.3 in the Technical Appendix.] For each of the distributions, the parameters can be obtained by maximizing the log-likelihood giving the convolution of $\epsilon_i=v_i - S \, u_i$.\n\n```{r}\n#| label: tbl-distributions\n#| tbl-cap: "Supported Distributions for the Inefficiency Term in sfaR"\n\ndistributions_df <- data.frame(\n  Distribution = c("Half-Normal", "Truncated Normal", "Exponential", \n                   "Rayleigh", "Generalized Exponential", "Skewed-Laplace (Truncated)",\n                   "Uniform", "Gamma", "Weibull", "Log-Normal", "Folded Normal", "Weighted Exponential"),\n  Parameters = c("1", "2", "1", "1", "1", "2", "1", "2", "2", "2", "2", "2"),\n  `Key References` = c("Aigner et al. (1977)", "Stevenson (1980)", "Meeusen & Vandenbroeck (1977)", \n                      "Oliviero (2014)", "Papadopoulos (2021)", "Wang (2012)", "Li (1996)", \n                      "Greene (1990)", "Tsionas (2007)", "Wang & Ye (2020)", "Leone et al. (1961)", "Gupta & Kundu (2009)"),\n  Function = c("sfa()", "sfa()", "sfa()", "sfa()", "sfa()", "sfa()", "sfa()", "sfa()", "sfa()", "sfa()", "sfa()", "sfa()")\n)\n\nknitr::kable(distributions_df, format = "markdown", align = "llll")\n```\n\nThe most commonly used distributions are the one-parameter half-normal distribution [@aig77] and the exponential distribution [@mee77]. Their large success is attributed to the simplicity of their density function and their availability in most statistical software (especially for the half-normal distribution). However, these distributions assumed a zero mode for the inefficiency implying that most DMUs will be deemed efficient. Two-parameter distributions like the truncated normal [@ste80; @kum87], and the gamma [@ste80; @beckers87; @greene90; @greene03] were later introduced to shift away from the zero mode distributions. A particular feature of these two distributions is that, under specific conditions they nest the half-normal and the exponential distributions, respectively. In the case of the gamma distribution, the density corresponding to $\epsilon_i$ does not have a close form, and @greene03 suggested the use of maximum simulated likelihood (MSL). If the previous four distributions are the standards in the stochastic frontier framework, other distributions are also introduced. For instance, the rayleigh [@oliv14; @hajar15; @wang20], and the generalized exponential [@papa21a] are one-parameter distributions, which have non-zero mode.^[@papa21a recommended a special case of the the generalized exponential distribution, introduced by @gupta99, where the shape parameter is set to two.] Another alternative two-parameter distribution is the log-normal [@wang20], which can be a good choice for certain type of datasets [@migon01; @rama12].\n\nA common feature of all the previous distributions is their positive skewness, which supposed a negative third moment for the distribution of $\epsilon_i$ when $S=1$. However, in practice, the third moment of $\epsilon_i$ can be positive [@sw09]. This generate a type I error, which might prevent the identification of the inefficiency distribution parameters [@olson80]. According to @wald82, the "wrong" skewness implies that the maximum likelihood and the OLS estimates of @eq-basic-sf will have the same slopes and there are no inefficiencies. A long debate has then emerged around the "wrong" skewness (see @papa21b). An advantage of the weibull and the truncated skewed-laplace distributions is to allow positive or negative skewness [@tsionas07; @wang12], and therefore identifying inefficiencies even when the OLS residuals has the "wrong" skewness. On another hand, the uniform distribution [@li96; @nguyen10; @lee14], which has a zero skewness, has been introduced to handle situations where the inefficiency distribution is symmetric around the mean. In this latter case, the OLS residuals will also be symmetric, and based on the previous distributions, no inefficiencies can be measured. Another advantage of the uniform distribution is to set a threshold on the inefficiency, which can provide useful economic information [@lee14].\n\n::: {.callout-important}\n## Do distributional assumptions even matter?\n\nIf as underlined by @kum20 the "choice of $u$ is often driven through available statistical software to implement the method rather than an underlying theoretical link between a model of productive inefficiency and the exact shape of the corresponding distribution", the **sfaR** package will fill in some gaps and allow practitioners to rigorously check differences in their results.^[See also @par14 for more discussion on the matter of the choice of $u$ distribution.] It is worth mentioning that if one is only interested on the features of the frontier, as long as inefficiency is not conditional on some variables, the OLS results should be sufficient. Moreover, it seems that DMUs ranking might not be affected by the distribution [@kum2000].\n:::\n\n## Basic Model Estimation\n\nHere's a simple example of estimating a stochastic frontier model:\n\n```{r}\n#| label: example-basic-estimation\n#| eval: false\n\n# Install and load sfaR package\n# install.packages("devtools")\n# devtools::install_github("hdakpo/sfaR")\nlibrary(sfaR)\n\n# Load example data\ndata("riceProdPhil", package = "sfaR")\n\n# Estimate a production frontier with half-normal inefficiency\nmodel_hn <- sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) + log(OTHER),\n                data = riceProdPhil,\n                distribution = "hnormal")\n\nsummary(model_hn)\n```\n\n```{r}\n#| label: example-distributions\n#| eval: false\n\n# Compare different distributions\nmodel_tn <- sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) + log(OTHER),\n                data = riceProdPhil,\n                distribution = "tnormal");\n\nmodel_exp <- sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) + log(OTHER),\n                 data = riceProdPhil,\n                 distribution = "exponential");\n\n# Compare models using information criteria\nAIC(model_hn, model_tn, model_exp)\nBIC(model_hn, model_tn, model_exp)\n```\n\n# Latent class stochastic frontiers and variants {#sec-modelcm}\n\nLatent class models recognize that firms may belong to different technological groups, each with its own frontier. This approach allows for unobserved heterogeneity in production technology.\n\n## Zero-Inefficiency Models\n\nThe zero-inefficiency stochastic frontier model [@kum13] allows for the possibility that some firms are fully efficient:\n\n```{r}\n#| label: example-zero-inefficiency\n#| eval: false\n\n# Estimate a zero-inefficiency model\nmodel_zi <- sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK),\n                data = riceProdPhil,\n                distribution = "hnormal",\n                zeroIneff = TRUE)\n\nsummary(model_zi)\n```\n\n## Contaminated Normal Models\n\nThese models [@wheat19] allow for outliers in the data:\n\n```{r}\n#| label: example-contaminated\n#| eval: false\n\n# Contaminated normal model (placeholder - actual implementation may vary)\n# This would handle outliers in the efficiency distribution\n```\n\n# Other models {#sec-other}\n\n## Sample selection stochastic frontier {#subsec-ss}\n\nSample selection models [@greene10] account for potential selection bias when not all observations are randomly sampled.\n\n## Metafrontiers {#subsec-meta}\n\nMetafrontier models [@batt04] allow comparison of efficiency across different technological groups:\n\n```{r}\n#| label: example-metafrontier\n#| eval: false\n\n# Metafrontier estimation (conceptual)\n# model_meta <- metafrontier(log(PROD) ~ log(AREA) + log(LABOR),\n#                           group = region,\n#                           data = riceProdPhil)\n```\n\n## Handling endogeneity in SFA {#subsec-endog}\n\nEndogeneity can be addressed through various approaches implemented in **sfaR**.\n\n# Introduction to the sfaR package {#sec-prespackage}\n\nThe **sfaR** package provides a comprehensive framework for stochastic frontier analysis. Key functions include:\n\n```{r}\n#| label: tbl-main-functions\n#| tbl-cap: "Main Functions in the sfaR Package"\n\nfunctions_df <- data.frame(\n  Function = c("sfa()", "lcmcf()", "metafr()", "sselec()", "efficiencyComp()"),\n  Purpose = c("Basic SFA estimation with various distributions", \n              "Latent class mixture models",\n              "Metafrontier estimation", \n              "Sample selection models",\n              "Efficiency computation and comparison"),\n  `Data Types` = c("Cross-sectional/Panel", "Cross-sectional", \n                   "Cross-sectional/Panel", "Cross-sectional", "Any")\n)\n\nknitr::kable(functions_df, format = "markdown", align = "lll")\n```\n\n## Post-estimation Analysis\n\n**sfaR** provides rich post-estimation capabilities:\n\n```{r}\n#| label: example-post-estimation\n#| eval: false\n\n# Extract efficiency scores\neff_scores <- efficiencies(model_hn)\n\n# Plot efficiency distribution\nhist(eff_scores, main = "Efficiency Distribution", \n     xlab = "Technical Efficiency", breaks = 20)\n\n# Summary statistics\nsummary(eff_scores)\n\n# Confidence intervals for efficiency\neff_ci <- efficiencies(model_hn, level = 0.95)\n```\n\n# Applications {#sec-illus}\n\n## Rice Production in the Philippines\n\nWe demonstrate **sfaR** using rice production data from the Philippines:\n\n```{r}\n#| label: application-rice\n#| eval: false\n\n# Load the data\ndata("riceProdPhil", package = "sfaR")\n\n# Explore the data\nhead(riceProdPhil)\nsummary(riceProdPhil)\n\n# Estimate multiple models for comparison\nmodels <- list(\n  hnormal = sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) + log(OTHER),\n                data = riceProdPhil, distribution = "hnormal"),\n  tnormal = sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) + log(OTHER),\n                data = riceProdPhil, distribution = "tnormal"),\n  exponential = sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) + log(OTHER),\n                    data = riceProdPhil, distribution = "exponential"),\n  gamma = sfa(log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) + log(OTHER),\n              data = riceProdPhil, distribution = "gamma")\n)\n\n# Compare models\nsapply(models, AIC)\nsapply(models, logLik)\n```\n\n## Efficiency Analysis\n\n```{r}\n#| label: efficiency-analysis\n#| eval: false\n\n# Extract efficiency scores from best model\nbest_model <- models$tnormal  # Assume truncated normal is best\neff_scores <- efficiencies(best_model)\n\n# Descriptive statistics\ncat("Efficiency Statistics:\n")\ncat("Mean:", mean(eff_scores), "\n")\ncat("Median:", median(eff_scores), "\n")\ncat("Min:", min(eff_scores), "\n")\ncat("Max:", max(eff_scores), "\n")\ncat("Standard Deviation:", sd(eff_scores), "\n")\n\n# Create efficiency plot\nlibrary(ggplot2)\neff_data <- data.frame(efficiency = eff_scores, id = 1:length(eff_scores))\n\nggplot(eff_data, aes(x = efficiency)) +\n  geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +\n  theme_minimal() +\n  labs(title = "Distribution of Technical Efficiency Scores",\n       x = "Technical Efficiency", y = "Frequency")\n```\n\n# Conclusion {#sec-concl}\n\nThe **sfaR** package represents a significant advancement in **R**-based tools for stochastic frontier analysis. By providing a comprehensive set of distributions, model specifications, and estimation methods, it enables researchers to conduct sophisticated efficiency analyses across various applications.\n\nKey contributions of **sfaR** include:\n\n1. **Comprehensive distribution support**: Twelve different distributions for modeling inefficiency\n2. **Advanced model variants**: Zero-inefficiency, contaminated normal, and latent class models\n3. **Flexible panel data models**: Various time-varying inefficiency specifications\n4. **Robust optimization**: Multiple algorithms for reliable estimation\n5. **Rich post-estimation tools**: Comprehensive efficiency analysis capabilities\n\nFuture developments may include additional panel data models, Bayesian estimation methods, and further robustness checks for model specification.\n\n# References {.unnumbered}\n\n::: {#refs}\n:::\n\n# Appendix {.unnumbered}\n\nFor detailed mathematical derivations and proofs of the likelihood functions and efficiency estimators, please refer to the Technical Appendix document (`sfaR_Technical_Appendix.qmd`).