% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sfalcmpanel.R
\name{sfalcmpanel}
\alias{sfalcmpanel}
\alias{bread.sfalcmpanel}
\alias{estfun.sfalcmpanel}
\alias{print.sfalcmpanel}
\title{Latent class stochastic frontier using panel data}
\usage{
sfalcmpanel(
  formula,
  uhet,
  vhet,
  thet,
  logDepVar = TRUE,
  data,
  idVar = NULL,
  timeVar = NULL,
  subset,
  weights,
  wscale = TRUE,
  S = 1L,
  modelType = "bc92a",
  udist = "hnormal",
  start = NULL,
  randStart = FALSE,
  whichStart = 2L,
  initAlg = "nm",
  initIter = 500,
  invariance = 2L,
  lcmClasses = 2,
  method = "bfgs",
  hessianType = 1,
  itermax = 2000L,
  printInfo = FALSE,
  tol = 1e-12,
  gradtol = 1e-06,
  stepmax = 0.1,
  qac = "marquardt"
)

\method{print}{sfalcmpanel}(x, ...)

bread.sfalcmpanel(x, ...)

estfun.sfalcmpanel(x, ...)
}
\arguments{
\item{formula}{A symbolic description of the model to be estimated based on
the generic function \code{formula} (see section \sQuote{Details}).}

\item{uhet}{A one-part formula to account for heteroscedasticity in the
one-sided error variance (see section \sQuote{Details}).}

\item{vhet}{A one-part formula to account for heteroscedasticity in the
two-sided error variance (see section \sQuote{Details}).}

\item{thet}{A one-part formula to account for technological heterogeneity in
the construction of the classes.}

\item{logDepVar}{Logical. Informs whether the dependent variable is logged
(\code{TRUE}) or not (\code{FALSE}). Default = \code{TRUE}.}

\item{data}{The data frame containing the data.}

\item{idVar}{Character. When \code{'data'} is not an object of class
\code{'pdata.frame'}, \code{'idVar'} defines the cross sections
identification. Default = \code{NULL}.}

\item{timeVar}{Character. When \code{'data'} is not an object of class
\code{'pdata.frame'}, \code{'timeVar'} defines the periods identification.
Default = \code{NULL}.}

\item{subset}{An optional vector specifying a subset of observations to be
used in the optimization process.}

\item{weights}{An optional vector of weights to be used for weighted
log-likelihood. Should be \code{NULL} or numeric vector with positive values.
When \code{NULL}, a numeric vector of 1 is used.}

\item{wscale}{Logical. When \code{weights} is not \code{NULL}, a scaling
transformation is used such that the the \code{weights} sum to the sample
size. Default = \code{TRUE}. When \code{FALSE} no scaling is used.}

\item{S}{If \code{S = 1} (default), a production (profit) frontier is
estimated. If \code{S = -1}, a cost frontier is estimated.}

\item{modelType}{Character string specifying the panel model to be estimated.
See \sQuote{Details} section.
\itemize{
\item Default = \code{'bc92a'} for the model discussed in Battese and Coelli
(1992).
\item A modified version (\code{'mbc92'}) of the previous model was also
presented in Battese and Coelli (1992).
\item \code{'bc92b'} implements the model presented in Cuesta and Orea (2002),
and Feng and Serletis (2009).
\item \code{'bc92c'} for the model in Alvarez \emph{et al.} (2006).
\item \code{'c00'} for the model in Cuesta (2000).
\item \code{'kw05'} for the model in Kumbhakar and Wang (2005).
\item \code{'mols93'} for the modified version of the model in
Lee and Schmidt (1993).
\item \code{'pl81'} for the time invariant inefficiency in
Pitt and Lee (1981).
}}

\item{udist}{Character string. Distribution specification for the one-sided
error term. Only the half normal distribution \code{'hnormal'} (Aigner
\emph{et al.}) is currently implemented.}

\item{start}{Numeric vector. Optional starting values for the maximum
likelihood (ML) estimation.}

\item{randStart}{Logical. Define if random starting values should be used for
M(S)L estimation. New starting values are obtained as old ones + draws from
normal distribution with std. deviation of 0.01. \code{'seed'} is not
considered here, then each run will provide different starting values
(unless a seed is set by the user before the run).}

\item{whichStart}{Integer. If \code{'whichStart = 1'}, the starting values
are obtained from the method of moments applied to the pooled data.
When \code{'whichStart = 2'} (Default), the model is initialized by solving
the classic SFA model for the homoscedastic pooled cross section data.
\code{'whichStart = 1'} can be fast especially in the case of maximum
simulated likelihood.}

\item{initAlg}{Character string specifying the algorithm used for
initializing and obtaining the starting values (when \code{'whichStart = 2'}).
Only \pkg{maxLik} package algorithms are available:
\itemize{ \item \code{'bfgs'}, for Broyden-Fletcher-Goldfarb-Shanno
(see \code{\link[maxLik:maxBFGS]{maxBFGS}})
\item \code{'bhhh'}, for Berndt-Hall-Hall-Hausman
(see \code{\link[maxLik:maxBHHH]{maxBHHH}})
\item \code{'nr'}, for Newton-Raphson (see \code{\link[maxLik:maxNR]{maxNR}})
\item \code{'nm'}, for Nelder-Mead - Default -
(see \code{\link[maxLik:maxNM]{maxNM}})
\item \code{'cg'}, for Conjugate Gradient
(see \code{\link[maxLik:maxCG]{maxCG}}) \item \code{'sann'}, for Simulated
Annealing (see \code{\link[maxLik:maxSANN]{maxSANN}})
}}

\item{initIter}{Maximum number of iterations for initializing algorithm.
Default \code{500}.}

\item{invariance}{Integer. Except in the case of \code{'modelType = 'bc92c''},
in the presence of heteroscedasticity, variables are supposed to be constant
over time for each cross section. When this is not the case, three options
are suggested to create constant variables: when \code{'invariance = 1L'},
the first period observation is used; when \code{'invariance = 2L'}, the last
period observation is used; and when \code{'invariance = 3L'}, the period
mean is used. The \code{'invariance'} option also applies to the
\code{'weights'} variable.}

\item{lcmClasses}{Number of classes to be estimated (default = \code{2}). A
maximum of five classes can be estimated.}

\item{method}{Optimization algorithm used for the estimation. Default =
\code{'bfgs'}. 11 algorithms are available: \itemize{ \item \code{'bfgs'},
for Broyden-Fletcher-Goldfarb-Shanno (see
\code{\link[maxLik:maxBFGS]{maxBFGS}}) \item \code{'bhhh'}, for
Berndt-Hall-Hall-Hausman (see \code{\link[maxLik:maxBHHH]{maxBHHH}}) \item
\code{'nr'}, for Newton-Raphson (see \code{\link[maxLik:maxNR]{maxNR}})
\item \code{'nm'}, for Nelder-Mead (see \code{\link[maxLik:maxNM]{maxNM}})
\item \code{'cg'}, for Conjugate Gradient
(see \code{\link[maxLik:maxCG]{maxCG}}) \item \code{'sann'}, for Simulated
Annealing (see \code{\link[maxLik:maxSANN]{maxSANN}}) \item \code{'ucminf'},
for a quasi-Newton type optimization with BFGS updating of the inverse
Hessian and soft line search with a trust region type monitoring of the input
to the line search algorithm (see \code{\link[ucminf:ucminf]{ucminf}})
\item \code{'mla'}, for general-purpose optimization based on
Marquardt-Levenberg algorithm (see \code{\link[marqLevAlg:mla]{mla}})
\item \code{'sr1'}, for Symmetric Rank 1 (see
\code{\link[trustOptim:trust.optim]{trust.optim}}) \item \code{'sparse'},
for trust regions and sparse Hessian
(see \code{\link[trustOptim:trust.optim]{trust.optim}}) \item
\code{'nlminb'}, for optimization using PORT routines (see
\code{\link[stats:nlminb]{nlminb}})}}

\item{hessianType}{Integer. If \code{1} (Default), analytic/numeric Hessian
is returned for all the distributions. If \code{2}, bhhh Hessian is
estimated (\eqn{g'g}).}

\item{itermax}{Maximum number of iterations allowed for optimization.
Default = \code{2000}.}

\item{printInfo}{Logical. Print information during optimization. Default =
\code{FALSE}.}

\item{tol}{Numeric. Convergence tolerance. Default = \code{1e-12}.}

\item{gradtol}{Numeric. Convergence tolerance for gradient. Default =
\code{1e-06}.}

\item{stepmax}{Numeric. Step max for \code{ucminf} algorithm. Default =
\code{0.1}.}

\item{qac}{Character. Quadratic Approximation Correction for \code{'bhhh'}
and \code{'nr'} algorithms. If \code{'stephalving'}, the step length is
decreased but the direction is kept. If \code{'marquardt'} (default), the
step length is decreased while also moving closer to the pure gradient
direction. See \code{\link[maxLik:maxBHHH]{maxBHHH}} and
\code{\link[maxLik:maxNR]{maxNR}}.}

\item{x}{an object of class sfalcmpanel (returned by the function
\code{\link{sfalcmpanel}}).}

\item{...}{additional arguments of frontier are passed to sfalcmpanel;
additional arguments of the print, bread, estfun, nobs methods are currently
ignored.}
}
\value{
\code{\link{sfalcmpanel}} returns a list of class
\code{'sfalcmpanel'} containing the following elements:

\item{call}{The matched call.}

\item{formula}{The estimated model.}

\item{S}{The argument \code{'S'}. See the section \sQuote{Arguments}.}

\item{typeSfa}{Character string. 'Stochastic Production/Profit Frontier, e =
v - u' when \code{S = 1} and 'Stochastic Cost Frontier, e = v + u' when
\code{S = -1}.}

\item{Nobs}{Total number of observations.}

\item{Nid}{Number of cross-sections in the panel data.}

\item{Vtime}{Vector of total number of periods of presence of each
cross-section.}

\item{Ntime}{Average periods of presence of each cross-section.}

\item{nXvar}{Number of explanatory variables in the production or cost
frontier.}

\item{nZHvar}{Number of variables in the logit specification of the finite
mixture model (i.e. number of covariates).}

\item{nuZUvar}{Number of variables explaining heteroscedasticity in the
one-sided error term.}

\item{nvZVvar}{Number of variables explaining heteroscedasticity in the
two-sided error term.}

\item{logDepVar}{The argument \code{'logDepVar'}. See the section
\sQuote{Arguments}.}

\item{nParm}{Total number of parameters estimated.}

\item{udist}{The argument \code{'udist'}. See the section
\sQuote{Arguments}.}

\item{startVal}{Numeric vector. Starting value for M(S)L estimation.}

\item{dataTable}{A data frame containing information on data
used for optimization along with residuals and fitted values of the OLS and
ML estimations, and the individual observation log-likelihood. When
\code{weights} is specified an additional variable is also provided in
\code{dataTable}.}

\item{modelType}{Spefication used for the panel model.}

\item{gHvar}{Matrix of variables used in the case of time varying
inefficiency when \code{'modelType %in% c('bc92a', 'bc92b', 'bc92c', 'kw05',
'c00', 'mols93')'} (for internal use).}

\item{invariance}{Methodology used to obtain time invariant exogenous
variables (in the case of heteroscedasticity).}

\item{initHalf}{When \code{start = NULL} and \code{whichStart == 2L}.
Initial ML estimation with half normal distribution for the one-sided error
term. Model to construct the starting values for
the latent class estimation. Object of class \code{'maxLik'} and
\code{'maxim'} returned.}

\item{isWeights}{Logical. If \code{TRUE} weighted log-likelihood is
maximized.}

\item{optType}{Optimization algorithm used.}

\item{nIter}{Number of iterations of the ML estimation.}

\item{optStatus}{Optimization algorithm termination message.}

\item{startLoglik}{Log-likelihood at the starting values.}

\item{nClasses}{The number of classes estimated.}

\item{mlLoglik}{Log-likelihood value of the M(S)L estimation.}

\item{mlParam}{Parameters obtained from M(S)L estimation.}

\item{mlParamMatrix}{Double. Matrix of ML parameters by class.}

\item{gradient}{Each variable gradient of the M(S)L estimation.}

\item{gradL_OBS}{Matrix. Each variable individual observation gradient of
the M(S)L estimation.}

\item{gradientNorm}{Gradient norm of the M(S)L estimation.}

\item{invHessian}{Covariance matrix of the parameters obtained from the
M(S)L estimation.}

\item{conditionNums}{Matrix. Condition number adding columns one by one.}

\item{hessianType}{The argument \code{'hessianType'}. See the section
\sQuote{Arguments}.}

\item{mlDate}{Date and time of the estimated model.}
}
\description{
\code{\link{sfalcmpanel}} is a symbolic formula based function for the
estimation of the latent class stochastic frontier model (LCM) in the case
of panel data. Several panel models are implemented: the time invariant
inefficiency model discussed in Pitt and Lee (1981), the time varying
efficiency models suggested in Kumbhakar (1990), Battese and Coelli (1992),
Cuesta (2000), Cuesta and Orea (2002), Kumbhakar and Wang (2005),
Alvarez \emph{et al.} (2006), Feng and Serletis (2009). We also suggested a
modified version of the model by Lee and Schmidt (1993) - see
\sQuote{Details} section.The model is estimated using maximum likelihood (ML).
See Orea and Kumbhakar (2004), Parmeter and Kumbhakar (2014, p282).
}
\details{
Only the half-normal distribution is possible for the one-sided error term.
Eleven optimization algorithms are available.

Depending on the specification, the function accounts for heteroscedasticity
in both one-sided and two-sided error terms as in
Reifschneider and Stevenson (1991), Caudill and Ford (1993),
Caudill \emph{et al.} (1995) and Hadri (1999).
Alvarez \emph{et al.} (2006) implements a version of the time varying
inefficiency using the scaling property as in Wang and Schmidt (2002).

The model can estimate up to five classes.

LCM is an estimation of a finite mixture of production functions. In the case
of the time invariant inefficiency model (Pitt and Lee (1981): \code{'pl81'})
the production frontier is defined as:

\deqn{y_{it} = \alpha_j + \mathbf{x_{it}^{\prime}} 
\bm{\beta_j} + v_{it|j} - Su_{i|j}}

\deqn{\epsilon_{it|j} = v_{it|j} - Su_{i|j}}

The contribution of cross-section \eqn{i} to the likelihood conditional on
class \eqn{j} is defined as:

The prior probability of using a particular technology can depend on some
covariates (namely the variables separating the observations into classes)
using a logit specification:

\deqn{\pi(i,j) = \frac{\exp{(\bm{\theta}_j'\mathbf{Z}_{hi})}}{
\sum_{m=1}^{J}\exp{(\bm{\theta}_m'\mathbf{Z}_{hi})}}}

with \eqn{\mathbf{Z}_h} the covariates, \eqn{\bm{\theta}} the coefficients
estimated for the covariates, and \eqn{\exp(\bm{\theta}_J'\mathbf{Z}_h)=1}.

The particularity of the prior probability is that it is time-invariant. In
the case of \code{'sfalcmpanel'}, the \eqn{\mathbf{Z}_h} are averaged for
each cross-section.
}
\examples{
# World production data
dataW <- worldprod
dataW$trend <- as.numeric(dataW$yr)
dataW <- pdata.frame(dataW, index = c("code", "yr"))

lcm2c <- sfalcmpanel(formula = ly ~ lk + ll + trend, modelType = "bc92a", 
data = dataW)

summary(lcm2c)

}
\references{
Aigner, D., Lovell, C. A. K., and P. Schmidt. 1977. Formulation
and estimation of stochastic frontier production function models.
\emph{Journal of Econometrics}, \bold{6}(1), 21--37.

Caudill, S. Aigner, D., Lovell, C. A. K., and Schmidt, P. 1977. Formulation
and estimation of stochastic frontier production function models.
\emph{Journal of Econometrics}, \bold{6}(1), 21--37.

Alvarez, A., Amsler, C., Orea, L., & Schmidt, P. (2006).
Interpreting and Testing the Scaling Property in Models where Inefficiency
Depends on Firm Characteristics. \emph{Journal of Productivity Analysis},
\bold{25}(3), 201-212. doi: 10.1007/s11123-006-7639-3.

Battese, G. E., & Coelli, T. J. (1992). Frontier production
functions, technical efficiency and panel data: With application to paddy
farmers in India. \emph{Journal of Productivity Analysis}, \bold{3}(1-2),
153-169. doi: 10.1007/bf00158774.

Battese, G. E., and Coelli, T. J. 1995. A model for technical inefficiency
effects in a stochastic frontier production function for panel data.
\emph{Empirical Economics}, \bold{20}(2), 325--332.

Caudill, S. B., and Ford, J. M. 1993. Biases in frontier estimation due to
heteroscedasticity. \emph{Economics Letters}, \bold{41}(1), 17--20.

Caudill, S. B., Ford, J. M., and Gropper, D. M. 1995. Frontier estimation
and firm-specific inefficiency measures in the presence of
heteroscedasticity. \emph{Journal of Business & Economic Statistics},
\bold{13}(1), 105--111.

Cuesta, R. A. (2000). A production model with firm-specific temporal
variation in technical inefficiency: With application to Spanish dairy farms.
\emph{Journal of Productivity Analysis}, \bold{13}(2), 139-158.
doi: Doi 10.1023/A:1017297831646.

Cuesta, R. A., & Orea, L. (2002). Mergers and technical efficiency in Spanish
savings banks: A stochastic distance function approach.
\emph{Journal of Banking & Finance}, \bold{26}(12), 2231-2247.
Doi 10.1016/S0378-4266(01)00184-4.

Feng, G., & Serletis, A. (2009). Efficiency and productivity of the US
banking industry, 1998–2005: evidence from the Fourier cost function
satisfying global regularity conditions.
\emph{Journal of Applied Econometrics}, \bold{24}(1), 105-138.
doi: https://doi.org/10.1002/jae.1021.

Hadri, K. 1999. Estimation of a doubly heteroscedastic stochastic frontier
cost function. \emph{Journal of Business & Economic Statistics},
\bold{17}(3), 359--363.

Kumbhakar, S. C. (1990). Production Frontiers, Panel Data, and Time-Varying
Technical Inefficiency. \emph{Journal of Econometrics}, \bold{46}(1-2),
201-211. doi: Doi 10.1016/0304-4076(90)90055-X.

Kumbhakar, S. C., & Wang, H.-J. (2005). Estimation of growth convergence
using a stochastic production frontier approach.
\emph{Economics Letters}, \bold{88}(3), 300-305.
doi: https://doi.org/10.1016/j.econlet.2005.01.023.

Orea, L., and S.C. Kumbhakar. 2004. Efficiency measurement using a latent
class stochastic frontier model. \emph{Empirical Economics}, \bold{29},
169--183.

Parmeter, C.F., and S.C. Kumbhakar. 2014. Efficiency analysis: A primer on
recent advances. \emph{Foundations and Trends in Econometrics}, \bold{7},
191--385.

Pitt, M. M., & Lee, L. F. (1981). The Measurement and Sources of Technical
Inefficiency in the Indonesian Weaving Industry.
\emph{Journal of Development Economics}, \bold{9}(1), 43-64.
doi: Doi 10.1016/0304-3878(81)90004-3.

Reifschneider, D., and Stevenson, R. 1991. Systematic departures from the
frontier: A framework for the analysis of firm inefficiency.
\emph{International Economic Review}, \bold{32}(3), 715--723.

Wang, H.J., and Schmidt, P. 2002. One-step and two-step estimation of the
effects of exogenous variables on technical efficiency levels. \emph{Journal
of Productivity Analysis}, \bold{18}:129--144.
}
\seealso{
\code{\link[=print.sfalcmpanel]{print}} for printing
\code{sfalcmpanel} object.

\code{\link[=summary.sfalcmpanel]{summary}} for creating and printing
summary results.

\code{\link[=coef.sfalcmpanel]{coef}} for extracting coefficients of the
estimation.

\code{\link[=efficiencies.sfalcmpanel]{efficiencies}} for computing
(in-)efficiency estimates.

\code{\link[=fitted.sfalcmpanel]{fitted}} for extracting the fitted frontier
values.

\code{\link[=ic.sfalcmpanel]{ic}} for extracting information criteria.

\code{\link[=logLik.sfalcmpanel]{logLik}} for extracting log-likelihood
value(s) of the estimation.

\code{\link[=residuals.sfalcmpanel]{residuals}} for extracting residuals of
the estimation.

\code{\link[=vcov.sfalcmpanel]{vcov}} for computing the variance-covariance
matrix of the coefficients.

\code{\link[=bread.sfalcmpanel]{bread}} for bread for sandwich estimator.

\code{\link[=estfun.sfalcmpanel]{estfun}} for gradient extraction for each
observation.
}
\keyword{latent-class}
\keyword{likelihood}
\keyword{models}
\keyword{optimize}
\keyword{panel-data}
